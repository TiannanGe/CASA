{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"float:left\">\n",
    "    <h1 style=\"width:450px\">Practical 4: Object-Oriented Programming</h1>\n",
    "    <h2 style=\"width:450px\">Getting to grips with Functions &amp; Packages</h2>\n",
    "</div>\n",
    "<div style=\"float:right\"><img width=\"100\" src=\"https://github.com/jreades/i2p/raw/master/img/casa_logo.jpg\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>&#9888; Important</b>: This is a very long practical and it's <em>not</em> expected that you will get through it in the alloted time. The priorities here should be tasks 1--4. Task 5 is something you will probably want to revist before the start of group work (because packges of functions are useful when multiple people are working on the same code). Task 6 will help you to understand <i>how</i> to build your own classes in greater detail, but it is enough to understand that classes exist in hierarchies (as covered in the live session).</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (Revisited). Why 'Obvious' is Not Always 'Right'\n",
    "\n",
    "Practical 3 is hard, so I want to provide _another_ chance for the concepts to bed in before we use them in an *object-oriented way through Pandas*. Yes, Week 5 will show how we combine concepts covered over the preceding two weeks in *practice* to do data science. \n",
    "\n",
    "So remember the finding from last week: if we don't really care about column order, then a dictionary of lists would be a nice way to handle data. And why should we care about column order? With our CSV file we saw what a pain it was to fix things when even a tiny thing like the layout of the columns changed. But if, instead, we could just reference the 'Description' column in the data set then it doesn't matter where that column actually is *and* we would know that all the descriptions would be *text*, while all the populations or prices would be *numbers*. Why is that? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1 The Way That Doesn't Work\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low (this time around).</div>\n",
    "\n",
    "Here are four rows of 'data' for city sizes organised by _row_ as a list-of-lists. Try printing out *just* the cities contained in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater London\n"
     ]
    }
   ],
   "source": [
    "myData = [\n",
    "    ['id', 'Name', 'Rank', 'Longitude', 'Latitude', 'Population'], \n",
    "    ['1', 'Greater London', '1', '-18162.92767', '6711153.709', '9787426'], \n",
    "    ['2', 'Greater Manchester', '2', '-251761.802', '7073067.458', '2553379'], \n",
    "    ['3', 'West Midlands', '3', '-210635.2396', '6878950.083', '2440986']\n",
    "]\n",
    "print(myData[1][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.1 Print a List of Cities\n",
    "\n",
    "Print out a list of every city in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cities in the data set are: Greater London, Greater Manchester, West Midlands\n"
     ]
    }
   ],
   "source": [
    "col    = myData[0].index('Name')#myData[0]指的是第一列,返回'Greater London'的下标是1\n",
    "cities = []\n",
    "for i in range(1,len(myData)):\n",
    "    cities.append(myData[i][col])\n",
    "    \n",
    "print(\"The cities in the data set are: \" + \", \".join(cities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Is Edinburgh in the List?\n",
    "\n",
    "Now write code to find out if `Edinburgh` is included in the list of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didn't find Edinburgh in the data set.\n"
     ]
    }
   ],
   "source": [
    "found = False\n",
    "\n",
    "for i in range(1, len(myData)):\n",
    "    if myData[i][col] == \"Edinburgh\":\n",
    "        print(\"Found Edinburgh in the data set!\")\n",
    "        found = True\n",
    "        break\n",
    "    else:\n",
    "        print(\"Didn't find Edinburgh in the data set.\")\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Task 1.2 The Way That Does Work\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low (this time around).</div>\n",
    "\n",
    "Compare that code to how it works for a dictionary-of-lists organised by _column_. Now try printing out the cities in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "myData = {\n",
    "    'id'         : [0, 1, 2, 3, 4, 5],\n",
    "    'Name'       : ['Greater London', 'Greater Manchester', 'Birmingham','Edinburgh','Inverness','Lerwick'],\n",
    "    'Rank'       : [1, 2, 3, 4, 5, 6],\n",
    "    'Longitude'  : [-0.128, -2.245, -1.903, -3.189, -4.223, -1.145],\n",
    "    'Latitude'   : [51.507, 53.479, 52.480, 55.953, 57.478, 60.155],\n",
    "    'Population' : [9787426, 2705000, 1141816, 901455, 70000, 6958],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2.1 Print a List of Cities\n",
    "\n",
    "Print out a list of every city in the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater London--Greater Manchester--Birmingham--Edinburgh--Inverness--Lerwick\n",
      "['Greater London', 'Greater Manchester', 'Birmingham', 'Edinburgh', 'Inverness', 'Lerwick']\n",
      "['Greater London', 'Greater Manchester', 'Birmingham', 'Edinburgh', 'Inverness', 'Lerwick']\n"
     ]
    }
   ],
   "source": [
    "# What cities are in the data set?\n",
    "print('--'.join(myData['Name']))#方法一\n",
    "a = myData.get('Name')#方法二\n",
    "print(a)\n",
    "\n",
    "a = []#方法三\n",
    "for i in myData['Name']:\n",
    "    a.append(i)\n",
    "\n",
    "print(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Is Edinburgh in the List?\n",
    "\n",
    "Now write code to find out if `Edinburgh` is included in the list of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Didn't find Edinburgh in the data set.\n"
     ]
    }
   ],
   "source": [
    "if 'Edinburgh' in \"Name\":\n",
    "    print(\"Found Edinburgh in the data set!\")\n",
    "else:\n",
    "    print(\"Didn't find Edinburgh in the data set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how even basic questions like \"Is Edinburgh in our list of data?\" are suddenly easy to answer? We no longer need to loop over the entire data set in order to find one data point. In addition, we know that everything in the 'Name' column will be a string, and that everything in the 'Longitude' column is a float, while the 'Population' column contains integers. So that's made life easier already. But let's test this out and see how it works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3 Appending a Column\n",
    "\n",
    "To give you a sense of how scaleable this approach to data is let's add a new column where the population is standardised to a z-score. Remember that the format for the z-score is: \n",
    "\n",
    "$$\n",
    "z = \\frac{x - \\bar{x}}{\\mu}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Calculate Mean & Std Dev\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low-ish.</div>\n",
    "\n",
    "Let's start by calculating the sample mean and standard deviation (use Google: `Python numpy mean...`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "City distribution has a mean 2,435,442 and standard deviation of 3,406,947.93.\n",
      "City distribution has a mean 2435442.5 and standard deviation of 3406947.9251788664.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Use numpy functions to calculate mean and standard deviation\n",
    "mean = np.mean(myData['Population'])\n",
    "std  = np.std(myData['Population'])\n",
    "print(f\"City distribution has a mean {mean:,.0f} and standard deviation of {std:,.2f}.\")#第一种出法,三进一\n",
    "print(\"City distribution has a mean {0} and standard deviation of {1}.\".format(mean, std))#第二种出法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy` gives us a way to calculate the mean and standard deviation _quickly_ and without having to reinvent the wheel. The other potentially new thing here is `{std:,.2f}`. This is about [string formatting](https://www.w3schools.com/python/ref_string_format.asp) and the main thing to recognise is that this means 'format this float with commas separating the thousands/millions and 2 digits to the right'. The link I've provided uses the slightly older approach of `<str>.format()` but the formatting approach is the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 For Loops Without For Loops\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium.</div>\n",
    "\n",
    "Now we're going to see something called a **List Comprehension**.\n",
    "\n",
    "In Python you will see code like this a lot: `[x for x in list]`. This syntax is known as a 'list comprehension' and is basically a `for` loop on one line with the output being assigned to a list. So we can apply an operation (converting to a string, subtracting a value, etc.) to every item in a list without writing out a full for loop.\n",
    "\n",
    "Here's a quick example just to show you what's going on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
     ]
    }
   ],
   "source": [
    "#列表解析\n",
    "demo = range(0,10) # 给demo定义一个0-10范围的区间\n",
    "print([x**2 for x in demo]) # x的幂次方, x递增,在10次内"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's apply this to our problem. We calculated the the mean and standard deviation above, so now we want to apply the z-score formula to every element of the Population list... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.158', '0.079', '-0.380', '-0.450', '-0.694', '-0.713']\n"
     ]
    }
   ],
   "source": [
    "rs = [(x - mean)/std for x in myData['Population']] # rs == result set\n",
    "print([f\"{x:.3f}\" for x in rs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.3 Appending\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: trivial</div>\n",
    "\n",
    "And now let's add it to the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3406947.9251788664\n"
     ]
    }
   ],
   "source": [
    "myData['Std. Population'] = std\n",
    "print(myData['Std. Population'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And just to show how everything is in a single data structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Greater London has a population of 9787426 and standardised score of 3406947.9251788664\n",
      "Greater Manchester has a population of 2705000 and standardised score of 3406947.9251788664\n",
      "Birmingham has a population of 1141816 and standardised score of 3406947.9251788664\n",
      "Edinburgh has a population of 901455 and standardised score of 3406947.9251788664\n",
      "Inverness has a population of 70000 and standardised score of 3406947.9251788664\n",
      "Lerwick has a population of 6958 and standardised score of 3406947.9251788664\n"
     ]
    }
   ],
   "source": [
    "for c in myData['Name']:\n",
    "    idx = myData['Name'].index(c)\n",
    "    g = myData['Population'][idx]\n",
    "    gg = myData['Std. Population']\n",
    "    #print(f\"{c} has a population of {myData['Population'][idx]:,} and standardised score of {myData['Std. Population'][idx]:.3f}\")\n",
    "    print(\"{0} has a population of {1} and standardised score of {2}\".format(c,g,gg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. 'Functionalising'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start trying to pull what we've learned over the past two weeks together by creating a a set of functions that will help us to:\n",
    "\n",
    "1. Download a file from a URL (checking if it has already _been_ downloaded to save bandwidth).\n",
    "2. Parse it as a CSV file and...\n",
    "3. Convert it to a Dictionary-of-Lists\n",
    "4. Perform some simple calculations using the resulting data.\n",
    "\n",
    "To be honest, there's not going to be much about writing our _own_ objects here, but we will be making use of them and, conceptually, an understanding of objects and classes is going to be super-useful for understanding what we're doing in the remainder of the term!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.1: Downloading from a URL\n",
    "\n",
    "Let's focus on the first part *first* because that's the precondition for everything else. If we can get the 'download a file from a URL' working then the rest will gradually fall into place through *iterative* improvments!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 Finding an Existing Answer\n",
    "\n",
    "First, let's be sensibly lazy--we've already written code to read a file from the Internet and turn it into a list of lists. So I've copy+pasted that into the code block below since we're going to start from this point; however, just to help you check your own understanding, I've removed a few bits and replacement with `??`. Sorry. 😈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "urlData has 11 rows and 4 columns.\n",
      "['Bangor', '18808', '53.228', '-4.128']\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "import csv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv\"\n",
    "\n",
    "urlData = [] # Somewhere to store the data\n",
    "\n",
    "response = urlopen(url) # Get the data using the urlopen function\n",
    "csvfile  = csv.reader(response.read().decode('utf-8').splitlines()) # Pass it over to the reader\n",
    "\n",
    "for row in csvfile:\n",
    "    urlData.append(row)\n",
    "\n",
    "print(\"urlData has \" + str(len(urlData)) + \" rows and \" + str(len(urlData[0])) + \" columns.\")\n",
    "print(urlData[-1]) # Check it worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get `urlData has 11 rows and 4 columns.` and a row that looks like this: `['Bangor', '18808', '53.228', '-4.128']`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 Getting Organised\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "Let's take the code above and modify it so that it is:\n",
    "\n",
    "1. A function that takes two arguments: a URL; and a destination filename.\n",
    "2. Implemented as a function that checks if a file exists already before downloading it again.\n",
    "\n",
    "You will find that the `os` module helps here because of the `path` function. And you will [need to Google](https://lmgtfy.app/?q=check+if+file+exists+python) how to test if a file exists. I would normally select a StackOverflow link in the results list over anything else because there will normally be an _explanation_ included of why a particular answer is a 'good one'. I also look at which answers got the most votes (not always the same as the one that was the 'accepted answer'). In this particular case, I also found [this answer](https://careerkarma.com/blog/python-check-if-file-exists/) useful.\n",
    "\n",
    "I would start by setting my inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvfile/Wikipedia-Cities.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv\"\n",
    "response = urlopen(url)\n",
    "csvfile  = csv.reader(response.read().decode('utf-8').splitlines())\n",
    "out = os.path.join(\"csvfile\",'Wikipedia-Cities.csv') \n",
    "print(out)# Print `out` if you aren't sure what this has done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3 Sketching the Function\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "Then I would sketch out how my function will work using comments. And the simplest thing to start with is checking whether the file has already been downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvfile/Wikipedia-Cities.csv found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "def get_url(src, dest):\n",
    "    \n",
    "    # Check if dest exists -- if it does\n",
    "    # then we can skip downloading the file,\n",
    "    # otherwise we have to download it!\n",
    "    if os.path.isfile(out):\n",
    "        print(f\"{dest} found!\")\n",
    "    else:\n",
    "        print(f\"{dest} *not* found!\")\n",
    "        \n",
    "get_url(url, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4 Fleshing Out the Function \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium, if you really explore what's going on in the function rather than just running it and moving on.</div>\n",
    "\n",
    "I would then flesh out the code so that it downloads the file if it isn't found and then, either way, returns the *local* file path for our CSV reader to extract:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvfile/Wikipedia-Cities.csv found locally!\n"
     ]
    }
   ],
   "source": [
    "def get_url(src, dest):#dest为输入的文件名变量,src为网址\n",
    "\n",
    "    if os.path.isfile(dest):#判断某一对象(需提供绝对路径)是否为文件\n",
    "        print(f\"{dest} found locally!\")\n",
    "    else:\n",
    "        print(f\"{dest} not found, downloading!\")\n",
    "        response = urlopen(src)#src作为第一个参数,被指向了url ,使用urlopen函数实例化了一个response对象\n",
    "        filedata = response.read().decode('utf-8')#想得到这个实例化的对象的具体内容可以使用read()方法,具体内容赋值为filedata\n",
    "        path = list(os.path.split(dest)[:1])#将文件名和路径分割开,[:1]或者[:-1]均能取到路径\"csvfile\"\n",
    "        print(path)#返回路径值\n",
    "        a = len(path)#返回路径值\n",
    "        b = path[0]#b等于1级路径名称,也就是下标为0,没有第二级\n",
    "        print(a)#打印路径值为1\n",
    "        print(b)#打印第一级路径名称\n",
    "        if len(path) >= 1 and path[0] != '':#如果子路径大于等于1并且路径不等于空\n",
    "            os.makedirs(os.path.join(*path), exist_ok=True)#os.makedirs()---创建文件夹,os.path.join拼接路径,exist_ok目录不存在时创建目录，存在时不会抛出异常。\n",
    "        with open(dest, 'w') as f:#with open是python用来打开本地文件的，他会在使用完毕后，自动关闭文件，无需手动书写close(),写入文件也用with open,使用\"w\"\n",
    "            f.write(filedata)#写入filedata\n",
    "        print(f\"Data written to {dest}!\")\n",
    "    return dest#\n",
    "        \n",
    "src = get_url(url, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>&#9888; Stop!</b> It really would be a good idea to put in the effort to make sense of how this function works. There is a lot going on here and understanding how this function works will help you to understand how to code. You should notice that we don't try to check if the data file contains any useful data! So if you download or create an empty file while testing, you won't necessarily get an error until you try to turn it into data afterwards!</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.2: Parse the CSV File\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "Now we turn to the next task: parsing the file if it's a CSV. This implies that it *might* not be so that's something we should also consider!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['City', 'Population', 'Latitude', 'Longitude'],\n",
       " ['Perth', '45770', '56.39583', '-3.43333'],\n",
       " ['Armagh', '14777', '54.3499', '-6.6546'],\n",
       " ['Dundee', '147268', '56.462', '-2.9707'],\n",
       " ['Colchester', '194706', '51.88861', '0.90361'],\n",
       " ['Salisbury', '40302', '51.07', '-1.79'],\n",
       " ['Portsmouth', '205056', '50.80583', '-1.08722'],\n",
       " ['Wakefield', '325837', '53.683', '-1.499'],\n",
       " ['Bradford', '522452', '53.792', '-1.754'],\n",
       " ['Lancaster', '138375', '54.047', '-2.801'],\n",
       " ['Bangor', '18808', '53.228', '-4.128']]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities-simple.csv\"\n",
    "response = urlopen(url)\n",
    "csvfile  = csv.reader(response.read().decode('utf-8').splitlines())\n",
    "out = os.path.join(\"csvfile\",'Wikipedia-Cities.csv') \n",
    "\n",
    "import csv\n",
    "\n",
    "def read_csv(c):\n",
    "    \n",
    "    csvdata = []\n",
    "    with open(c, 'r') as f:#文件读模式,\n",
    "        csvr = csv.reader(f)#csvr等于使用scv的reader函数读取f数据\n",
    "        \n",
    "        for r in csvr:#每一行在vsvr中\n",
    "            csvdata.append(r)#从csvdata依次加入每一行\n",
    "    \n",
    "    # Return list of lists\n",
    "    return csvdata#输出最终文件,csv转为列表\n",
    "\n",
    "read_csv(src)\n",
    "#read_csv('foo.bar') # <- Notice what happens if you try to run this code\n",
    "#read_csv('Practical-04-Objects-Answers.ipynb') # Or this code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get:\n",
    "\n",
    "```\n",
    "[['City', 'Population', 'Latitude', 'Longitude'],\n",
    " ['Perth', '45770', '56.39583', '-3.43333'],\n",
    " ['Armagh', '14777', '54.3499', '-6.6546'],\n",
    " ['Dundee', '147268', '56.462', '-2.9707'],\n",
    " ['Colchester', '194706', '51.88861', '0.90361'],\n",
    " ['Salisbury', '40302', '51.07', '-1.79'],\n",
    " ['Portsmouth', '205056', '50.80583', '-1.08722'],\n",
    " ['Wakefield', '325837', '53.683', '-1.499'],\n",
    " ['Bradford', '522452', '53.792', '-1.754'],\n",
    " ['Lancaster', '138375', '54.047', '-2.801'],\n",
    " ['Bangor', '18808', '53.228', '-4.128']]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.3: Convert the CSV into a DoL\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can focus on converting the CSV data to a dictionary-of-lists! We're going to start with the *same* function name but expand what the function *does*. This kind of *iteration* is common in software development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'City': []}\n",
      "{'City': [], 'Population': []}\n",
      "{'City': [], 'Population': [], 'Latitude': []}\n",
      "{'City': [], 'Population': [], 'Latitude': [], 'Longitude': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'City': ['Perth',\n",
       "  'Armagh',\n",
       "  'Dundee',\n",
       "  'Colchester',\n",
       "  'Salisbury',\n",
       "  'Portsmouth',\n",
       "  'Wakefield',\n",
       "  'Bradford',\n",
       "  'Lancaster',\n",
       "  'Bangor'],\n",
       " 'Population': ['45770',\n",
       "  '14777',\n",
       "  '147268',\n",
       "  '194706',\n",
       "  '40302',\n",
       "  '205056',\n",
       "  '325837',\n",
       "  '522452',\n",
       "  '138375',\n",
       "  '18808'],\n",
       " 'Latitude': ['56.39583',\n",
       "  '54.3499',\n",
       "  '56.462',\n",
       "  '51.88861',\n",
       "  '51.07',\n",
       "  '50.80583',\n",
       "  '53.683',\n",
       "  '53.792',\n",
       "  '54.047',\n",
       "  '53.228'],\n",
       " 'Longitude': ['-3.43333',\n",
       "  '-6.6546',\n",
       "  '-2.9707',\n",
       "  '0.90361',\n",
       "  '-1.79',\n",
       "  '-1.08722',\n",
       "  '-1.499',\n",
       "  '-1.754',\n",
       "  '-2.801',\n",
       "  '-4.128']}"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv(src):\n",
    "    \n",
    "    csvdata = {} # An empty dictionary-of-lists\n",
    "    \n",
    "    with open(src, 'r') as f:\n",
    "        csvr = csv.reader(f)\n",
    "        csvcols = next(csvr)#为什么next函数可以取列名          \n",
    "        for c in csvcols:\n",
    "            csvdata[c] = []\n",
    "            print(csvdata)#csvdata是字典,字典加入内容是用[\"里面为文本\"]定义为表头,本次只加入表头,通过等于号赋值了值,本次是赋值了空值[]\n",
    "        for r in csvr: \n",
    "            for u, c in enumerate(csvcols):\n",
    "                csvdata[c].append(r[u])\n",
    "    return csvdata\n",
    "\n",
    "read_csv(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get something that starts:\n",
    "```\n",
    "{'City': ['Perth',\n",
    "  'Armagh',\n",
    "  'Dundee',\n",
    "  'Colchester',\n",
    "  'Salisbury',\n",
    "  'Portsmouth',\n",
    "  'Wakefield',\n",
    "  'Bradford',\n",
    "  'Lancaster',\n",
    "  'Bangor'],\n",
    " 'Population': ['45770',\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.4: Adding Docstring\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "We've assumed that the first row of our data set is always a _header_ (i.e. list of column names). If it's not then this code is going to have problems. A _robust_ function would allow us to specify column names, skip rows, etc. when we create the data structure, but let's not get caught up in that level of detail. Notice that I've also, for the first time:\n",
    "\n",
    "1. Used the docstring support offered by Python. You'll be able to use `help(...)` and get back the docstring help!\n",
    "2. Provided hints to Python about the expected input and output data types. This can help to ensure consistency and is also critical in testing / continuous integration when working with others on a codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'City': ['Perth',\n",
       "  'Armagh',\n",
       "  'Dundee',\n",
       "  'Colchester',\n",
       "  'Salisbury',\n",
       "  'Portsmouth',\n",
       "  'Wakefield',\n",
       "  'Bradford',\n",
       "  'Lancaster',\n",
       "  'Bangor'],\n",
       " 'Population': ['45770',\n",
       "  '14777',\n",
       "  '147268',\n",
       "  '194706',\n",
       "  '40302',\n",
       "  '205056',\n",
       "  '325837',\n",
       "  '522452',\n",
       "  '138375',\n",
       "  '18808'],\n",
       " 'Latitude': ['56.39583',\n",
       "  '54.3499',\n",
       "  '56.462',\n",
       "  '51.88861',\n",
       "  '51.07',\n",
       "  '50.80583',\n",
       "  '53.683',\n",
       "  '53.792',\n",
       "  '54.047',\n",
       "  '53.228'],\n",
       " 'Longitude': ['-3.43333',\n",
       "  '-6.6546',\n",
       "  '-2.9707',\n",
       "  '0.90361',\n",
       "  '-1.79',\n",
       "  '-1.08722',\n",
       "  '-1.499',\n",
       "  '-1.754',\n",
       "  '-2.801',\n",
       "  '-4.128']}"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv(src:str) -> dict:\n",
    "    \"\"\"\n",
    "    Converts a CSV file to a dictionary-of-lists (dol),\n",
    "    using the first row to create column names.\n",
    "    \n",
    "    :param src: ??\n",
    "    :returns: ??\n",
    "    \"\"\"\n",
    "    csvdata = {} # An empty dictionary-of-lists\n",
    "    \n",
    "    with open(src, 'r') as f:\n",
    "        csvr = csv.reader(f)\n",
    "        \n",
    "        # Read in our column names and\n",
    "        # initialise the dictionary-of-lists\n",
    "        csvcols = next(csvr) \n",
    "        for c in csvcols:\n",
    "            csvdata[c] = []\n",
    "        \n",
    "        # Notice this code is still the same, \n",
    "        # we just used next(csvr) to get the \n",
    "        # header row first!\n",
    "        for r in csvr: \n",
    "            # Although you can often assume that the order \n",
    "            # of the keys is the same, Python doesn't \n",
    "            # guarantee it; this way we will always make\n",
    "            # the correct assignment.\n",
    "            for idx, c in enumerate(csvcols):\n",
    "                csvdata[c].append(r[idx])\n",
    "    \n",
    "    # Return dictionary of lists\n",
    "    return csvdata\n",
    "\n",
    "ds = read_csv(src)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3496532743.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [151]\u001b[0;36m\u001b[0m\n\u001b[0;31m    help(??)\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "help(??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: City, Population, Latitude, Longitude\n",
      "First two cities are: ['Perth', 'Armagh']\n",
      "First two populations are: ['45770', '14777']\n",
      "First two latitudes are: ['56.39583', '54.3499']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns are: \" + \", \".join(ds.keys()))\n",
    "print(f\"First two cities are: {ds['City'][:2]}\")\n",
    "print(f\"First two populations are: {ds['Population'][:2]}\")\n",
    "print(f\"First two latitudes are: {ds['Latitude'][:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer should look like:\n",
    "```\n",
    "Columns are: City, Population, Latitude, Longitude\n",
    "First two cities are: ['Perth', 'Armagh']\n",
    "First two populations are: ['45770', '14777']\n",
    "First two latitudes are: ['56.39583', '54.3499']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.5: Fixing Data Types\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium.</div>\n",
    "\n",
    "If you look closely at the above, you'll see that *everything* is a string, including the latitudes, longitudes, and populations, which are clearly numeric data types. Here's a 'simple' way to specify a `dtype` list to hold the _data type_ for each column. I'm also going to introduce you the `zip` function here as it has many uses with geographic data (especially converting lat/long to points)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.1 Demonstrating Zip\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column         City should be type: str\n",
      "Column   Population should be type: int\n",
      "Column     Latitude should be type: float\n",
      "Column    Longitude should be type: float\n"
     ]
    }
   ],
   "source": [
    "cols  = ['City', 'Population', 'Latitude', 'Longitude'] # <- Column name\n",
    "dtype = [str, int, float, float]                        # <- Column data type\n",
    "\n",
    "# 'Zips up' these two lists into an iterator! So this will \n",
    "# take element 0 from *each* list and pass them to `col` as\n",
    "# a list-like 'tuple' (meaning there is a col[0] and a col[1]).\n",
    "for col in zip(cols, dtype):\n",
    "    colname = col[0]\n",
    "    coltype = col[1]\n",
    "    \n",
    "    # Notice the more advanced formatting here:\n",
    "    # - `>12` means right-align with up to 12 characters of whitespace; notice the last line!\n",
    "    # - `coltype.__name__` gives us the name of the data type, rather than a '<class...>' output.\n",
    "    print(f\"Column {colname:>12} should be type: {coltype.__name__}\")#>12为右对齐的意思,最多12个字符的空白"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5.2 A Function to Convert Data Types\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low, as I've provided a function.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the raw data to data of the appropriate\n",
    "# type: 'column data' (cdata) -> 'column type' (ctype)\n",
    "def to_type(cdata, ctype):\n",
    "    # If a string\n",
    "    if isinstance(cdata, str):#isinstance() 函数来判断一个对象是否是一个已知的类型，类似 type()。\n",
    "        try:#尝试,通常用于找错\n",
    "            if ctype==bool:\n",
    "                return cdata==True\n",
    "            else:\n",
    "                return ctype(cdata)\n",
    "        except TypeError:\n",
    "            return cdata\n",
    "    \n",
    "    # Not a string (assume list)\n",
    "    else: \n",
    "        fdata = []\n",
    "        for c in cdata:\n",
    "            try:\n",
    "                if ctype==bool:\n",
    "                    fdata.append( c=='True' )\n",
    "                else:\n",
    "                    fdata.append( ctype(c) )\n",
    "            except:\n",
    "                fdata.append( c )\n",
    "        return fdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'City': ['Perth', 'Armagh', 'Dundee', 'Colchester', 'Salisbury', 'Portsmouth', 'Wakefield', 'Bradford', 'Lancaster', 'Bangor'], 'Population': [45770, 14777, 147268, 194706, 40302, 205056, 325837, 522452, 138375, 18808], 'Latitude': [56.39583, 54.3499, 56.462, 51.88861, 51.07, 50.80583, 53.683, 53.792, 54.047, 53.228], 'Longitude': [-3.43333, -6.6546, -2.9707, 0.90361, -1.79, -1.08722, -1.499, -1.754, -2.801, -4.128]}\n"
     ]
    }
   ],
   "source": [
    "# Now apply this! We'll copy the data to \n",
    "# new data structure only so that we know\n",
    "# we're not overwriting `ds` until we're sure\n",
    "# that the code works.\n",
    "ds2 = {}\n",
    "cols  = ['City', 'Population', 'Latitude', 'Longitude'] # <- Column name\n",
    "dtype = [str, int, float, float]                        # <- Column data type\n",
    "for col in zip(cols, dtype):\n",
    "    colname = col[0]\n",
    "    coltype = col[1]\n",
    "    ds2[colname] = to_type( ds[colname], coltype )\n",
    "print(ds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the output here to the output from `ds` up above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns are: City, Population, Latitude, Longitude\n",
      "First two cities are: ['Perth', 'Armagh']\n",
      "First two populations are: [45770, 14777]\n",
      "First two latitudes are: [56.39583, 54.3499]\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns are: \" + \", \".join(ds2.keys()))\n",
    "print(f\"First two cities are: {ds2['City'][:2]}\")\n",
    "print(f\"First two populations are: {ds2['Population'][:2]}\")\n",
    "print(f\"First two latitudes are: {ds2['Latitude'][:2]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the followg:\n",
    "```\n",
    "Columns are: City, Population, Latitude, Longitude\n",
    "First two cities are: ['Perth', 'Armagh']\n",
    "First two populations are: [45770, 14777]\n",
    "First two latitudes are: [56.39583, 54.3499]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2.6: Checking Basic Functionality\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium</div>\n",
    "\n",
    "Now that we've got our data structure all set up correctly (appropriate names, data types, etc.) let's see if it works by testing out some of our previous operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average population is 165,335.10\n",
      "Westernmost city is Armagh\n",
      "Northernmost city is Dundee\n",
      "Southernmost city is Portsmouth\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # We'll need this to apply functions to lists easily\n",
    "\n",
    "print(f\"Average population is {np.mean(ds2['Population']):,.2f}\")\n",
    "print(f\"Westernmost city is {ds2['City'][np.where(ds2['Longitude']==np.min(ds2['Longitude']))[0][0]]}\")\n",
    "print(f\"Northernmost city is {ds2['City'][np.where(ds2['Latitude']==np.max(ds2['Latitude']))[0][0]]}\")\n",
    "print(f\"Southernmost city is {ds2['City'][np.where(ds2['Latitude']==np.min(ds2['Latitude']))[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get the following:\n",
    "\n",
    "```\n",
    "Average population is 165,335.10\n",
    "Westernmost city is Armagh\n",
    "Northernmost city is Dundee\n",
    "Southernmost city is Portsmouth\n",
    "```\n",
    "\n",
    "There are a few things to understand here:\n",
    "\n",
    "1. Where we want to find something else in the data *based on that value* then things get a little more complex: we use `np.min` to find the smallest value in the data, but we don't know *where* in the list that value actually *was* so we use `np.where` to find out which indexes match the minimum value. In this data set it's easy because there's one, and only one value that matches. But you'd need to do some clever thinking about how to handle ties.\n",
    "2. `np.where` returns a complex data structure (list-of-lists, essentially) so we need to pull the value we need out of that data in order to actually find the list index we need and look up the `City` name associated with, for example, the minium value in the data. That bit (`[0][0]`) is a bit clunky, but right now we're not too worried about it.\n",
    "\n",
    "**Notice** that we do *all* of this without using a `for` loop or variables to keep track of what we've found... You *could* also use a `for` loop to answer each of these questions (see the example below), but hopefully you see what the way we've used above is more *elegant* (it's also faster):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum longitude is -6.6546\n",
      "Westernmost city is Armagh\n"
     ]
    }
   ],
   "source": [
    "min_long = 180\n",
    "min_idx  = -1\n",
    "\n",
    "for l in ds2['Longitude']:\n",
    "    if l < min_long: min_long = l\n",
    "print(f\"Minimum longitude is {min_long}\")\n",
    "\n",
    "for idx, l2 in enumerate(ds2['Longitude']):\n",
    "    if l2==min_long:\n",
    "        min_idx = idx\n",
    "        break\n",
    "\n",
    "print(f\"Westernmost city is {ds2['City'][min_idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Was it Worth It?\n",
    "\n",
    "<div class=\"alert alert-block alert-success\"><b>Difficulty level</b>: Low</div>\n",
    "\n",
    "At this point it's worth asking: was all this *worth* it? Let's see! \n",
    "\n",
    "The best way to test is to use a *different* data set and see if we've solved the 'hard-coding' problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/Wikipedia-Cities-full.csv found locally!\n"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/jreades/fsds/master/data/src/Wikipedia-Cities.csv\"\n",
    "out = os.path.join('data','Wikipedia-Cities-full.csv')\n",
    "\n",
    "cols  = ['City', 'Population', 'Latitude', 'Longitude']\n",
    "dtype = [str, int, float, float]\n",
    "\n",
    "untyped_dol = read_csv(get_url(url, out))\n",
    "\n",
    "typed_dol = {}\n",
    "for col in zip(cols, dtype):\n",
    "    colname = col[0]\n",
    "    coltype = col[1]\n",
    "    typed_dol[ colname ] = to_type(untyped_dol[colname], coltype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average population is 202,283.36\n",
      "Westernmost city is Derry\n",
      "Northernmost city is Inverness, Inerness, Inbhir Nis\n",
      "Southernmost city is Truro\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average population is {np.mean(typed_dol['Population']):,.2f}\")\n",
    "print(f\"Westernmost city is {typed_dol['City'][np.where(typed_dol['Longitude']==np.min(typed_dol['Longitude']))[0][0]]}\")\n",
    "print(f\"Northernmost city is {typed_dol['City'][np.where(typed_dol['Latitude']==np.max(typed_dol['Latitude']))[0][0]]}\")\n",
    "print(f\"Southernmost city is {typed_dol['City'][np.where(typed_dol['Latitude']==np.min(typed_dol['Latitude']))[0][0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get:\n",
    "\n",
    "```\n",
    "Average population is 202,283.36\n",
    "Westernmost city is Derry\n",
    "Northernmost city is Inverness, Inerness, Inbhir Nis\n",
    "Southernmost city is Truro\n",
    "```\n",
    "\n",
    "So we used all the same code as for the subset of the data but changed *nothing*. And this is even though the column order changed (print out the first row of each file if you don't believe me) *and* the number of columns changed *and* our city column now contains commas! So what this has given us is a much more flexible way not only to *access* the data, but also to *work* with it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4. More Functions!\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\"><b>Difficulty level</b>: Medium</div>\n",
    "\n",
    "Here is the skeleton of a function to replace the `np.where(column==np.[min|max|...](column))[0][0]` code. There are a few ways to do this: \n",
    "\n",
    "1. You could use if/else/elif and do different things based on testing against the specified string\n",
    "2. You could try to find a function in `numpy` that matches the specified string\n",
    "3. You could try to `eval` the code, but I really wouldn't recommend this for security reasons\n",
    "\n",
    "I have gone with a combination of 1 and 2, but you will need to really read the code to understand how it works. I've left the docstring for you to complete. This isn't the best function since it makes some assumptions about the types of data that it might be passed to the function: this is where *Object-Oriented Programming* could come to the rescue! If we had different column *types* (e.g. String, Float, Int) then we could have different *versions* of `find_val` that performed the same *function* (find a value) but did this completely differently depending on the data. This is what *methods* do!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "52.801835\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def find_val(col:list, val:str):\n",
    "    \"\"\"\n",
    "    ??\n",
    "    \"\"\"\n",
    "    if val in dir(np) and callable(getattr(np, val)):\n",
    "        func = getattr(np, val) # <--- What does this do???\n",
    "        if val in ['min','max']:\n",
    "            return np.where(col==func(col))[0][0]\n",
    "        else:\n",
    "            return func(col)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "print(find_val(typed_dol['Latitude'], 'min'))\n",
    "print(find_val(typed_dol['Latitude'], 'median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average population is 202,283.36\n",
      "Westernmost city is Derry\n",
      "Northernmost city is Inverness, Inerness, Inbhir Nis\n",
      "Southernmost city is Truro\n"
     ]
    }
   ],
   "source": [
    "print(f\"Average population is {find_val(typed_dol['Population'],'mean'):,.2f}\")\n",
    "print(f\"Westernmost city is {typed_dol['City'][find_val(typed_dol['Longitude'],'min')]}\")\n",
    "print(f\"Northernmost city is {typed_dol['City'][find_val(typed_dol['Latitude'],'max')]}\")\n",
    "print(f\"Southernmost city is {typed_dol['City'][find_val(typed_dol['Latitude'],'min')]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have streaminlined the code still further and implemented a fairly generic 'helper' function that uses `numpy` to perform calculations on a column of data (assuming it's numeric). We could, of course, extend this further, to handle strings and other data types, but we're going to see a *better* way to do all of this *next* week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5. Creating a Package from Functions\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>Difficulty level</b>: Hard.</div>\n",
    "\n",
    "Below is code to create a package called `dtools` (i.e. data tools) by converting the notebook into a Python script file called `__init__.py` that sits in the `dtools` directory. This is the first step to creating a package from code that is *already* working in a Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.1 Create a Directory\n",
    "\n",
    "When creating your own package, everything goes into a directory whose name is the name of the package. In other words, if you wanted to create a package called `my_stuff` then you'd need to *first* create a directory called `my_staff` in the *current working directory* (i.e. wherever you are keeping your Notbooks).\n",
    "\n",
    "We can create the directory using `mkdir` (the `!` means 'run this [Linux] command'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p 'dtools'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.2 Create \\_\\_init\\_\\_.py\n",
    "\n",
    "More complex packages will have lots of stuff going on inside their 'root' directory, but we're keeping it simple and only need to create and fill in *one* file inside the `dtools` directory: `__init__.py`. This is a convention.\n",
    "\n",
    "We can create this file two ways: \n",
    "\n",
    "1. By creating an empty file with that name in `dtools` (e.g. `!touch dtools/__init__.py` would work!)\n",
    "2. By converting *this* entire notebook to a Python script and then removing all the stuff that *is not* a function that we need to keep.\n",
    "\n",
    "The 'hybrid' way, which I'm going to suggest you use so you get some more experience, would be to convert this notebook to a Python script file, open it, and then copy the functions out into `__init__.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook Practical-04-Objects.ipynb to python\n",
      "[NbConvertApp] Writing 42453 bytes to dtools/notebook.py\n"
     ]
    }
   ],
   "source": [
    "!touch dtools/__init__.py\n",
    "# Comment out so we don't automatically re-run this code every time\n",
    "!jupyter nbconvert --ClearOutputPreprocessor.enabled=True \\\n",
    "    --to python --output=dtools/notebook.py \\\n",
    "    Practical-04-Objects.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.3 Extract Code to Init\n",
    "\n",
    "You now need to open `notebook.py` and find+copy the following functions into `__init__.py`:\n",
    "\n",
    "1. `get_url`\n",
    "2. `read_csv` \n",
    "3. `to_type` \n",
    "4. `find_val`\n",
    "\n",
    "And don't forget to find all the `import` statements (including `from x import y`) and copy those as well!\n",
    "\n",
    "You should then be able to run the code below and can always compare it to my version [on GitHub](https://github.com/jreades/fsds/blob/master/practicals/dtools/__init__.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5.6 Test\n",
    "\n",
    "The next two lines of code allow you to repeatedly edit an imported package without having to restart the entire Python notebook. So whenever Jupyter sees a change to `dtools/__init__.py` it will reload the package and update the code without you having to do anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.1 Import\n",
    "\n",
    "And now we should be able to import the package and start using the functions that we defined..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csvfile/Wikipedia-Cities.csv\n",
      "csvfile/Wikipedia-Cities.csv found locally!\n",
      "Help on function read_csv in module dtools:\n",
      "\n",
      "read_csv(src)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import dtools\n",
    "help(dtools.read_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.2 Use Read_CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/crime-sample.csv found locally!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>Year</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11667185</td>\n",
       "      <td>JC237601</td>\n",
       "      <td>04/20/2019 11:00:00 PM</td>\n",
       "      <td>BURGLARY</td>\n",
       "      <td>FORCIBLE ENTRY</td>\n",
       "      <td>COMMERCIAL / BUSINESS OFFICE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.751307</td>\n",
       "      <td>-87.603468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11909178</td>\n",
       "      <td>JC532226</td>\n",
       "      <td>12/02/2019 10:35:00 AM</td>\n",
       "      <td>DECEPTIVE PRACTICE</td>\n",
       "      <td>FRAUD OR CONFIDENCE GAME</td>\n",
       "      <td>GROCERY FOOD STORE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.903997</td>\n",
       "      <td>-87.643230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11852571</td>\n",
       "      <td>JC462365</td>\n",
       "      <td>10/06/2019 04:50:00 PM</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>AGGRAVATED DOMESTIC BATTERY - OTHER DANGEROUS ...</td>\n",
       "      <td>CLEANING STORE</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.880329</td>\n",
       "      <td>-87.758473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11804855</td>\n",
       "      <td>JC405161</td>\n",
       "      <td>08/23/2019 10:00:00 PM</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>OVER $500</td>\n",
       "      <td>STREET</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.924384</td>\n",
       "      <td>-87.641442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11808164</td>\n",
       "      <td>JC409088</td>\n",
       "      <td>08/26/2019 12:00:00 AM</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>ALLEY</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.755797</td>\n",
       "      <td>-87.634426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>11923269</td>\n",
       "      <td>JC548861</td>\n",
       "      <td>12/13/2019 09:20:00 PM</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>SIMPLE</td>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.890384</td>\n",
       "      <td>-87.624110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>11728933</td>\n",
       "      <td>JC313883</td>\n",
       "      <td>06/20/2019 05:02:00 AM</td>\n",
       "      <td>BATTERY</td>\n",
       "      <td>DOMESTIC BATTERY SIMPLE</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.921325</td>\n",
       "      <td>-87.779766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>11685629</td>\n",
       "      <td>JC261285</td>\n",
       "      <td>05/10/2019 05:15:00 PM</td>\n",
       "      <td>ASSAULT</td>\n",
       "      <td>AGG PRO.EMP: HANDGUN</td>\n",
       "      <td>SCHOOL, PUBLIC, GROUNDS</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>42.003359</td>\n",
       "      <td>-87.705800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>11760201</td>\n",
       "      <td>JC351547</td>\n",
       "      <td>07/16/2019 04:16:00 PM</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>RETAIL THEFT</td>\n",
       "      <td>GROCERY FOOD STORE</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>42.019399</td>\n",
       "      <td>-87.675049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>11648994</td>\n",
       "      <td>JC217114</td>\n",
       "      <td>04/08/2019 11:10:00 PM</td>\n",
       "      <td>NARCOTICS</td>\n",
       "      <td>MANU/DELIVER: HEROIN (WHITE)</td>\n",
       "      <td>ABANDONED BUILDING</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2019</td>\n",
       "      <td>41.877933</td>\n",
       "      <td>-87.729141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID Case Number                    Date        Primary Type  \\\n",
       "0   11667185    JC237601  04/20/2019 11:00:00 PM            BURGLARY   \n",
       "1   11909178    JC532226  12/02/2019 10:35:00 AM  DECEPTIVE PRACTICE   \n",
       "2   11852571    JC462365  10/06/2019 04:50:00 PM             BATTERY   \n",
       "3   11804855    JC405161  08/23/2019 10:00:00 PM               THEFT   \n",
       "4   11808164    JC409088  08/26/2019 12:00:00 AM             BATTERY   \n",
       "..       ...         ...                     ...                 ...   \n",
       "95  11923269    JC548861  12/13/2019 09:20:00 PM             ASSAULT   \n",
       "96  11728933    JC313883  06/20/2019 05:02:00 AM             BATTERY   \n",
       "97  11685629    JC261285  05/10/2019 05:15:00 PM             ASSAULT   \n",
       "98  11760201    JC351547  07/16/2019 04:16:00 PM               THEFT   \n",
       "99  11648994    JC217114  04/08/2019 11:10:00 PM           NARCOTICS   \n",
       "\n",
       "                                          Description  \\\n",
       "0                                      FORCIBLE ENTRY   \n",
       "1                            FRAUD OR CONFIDENCE GAME   \n",
       "2   AGGRAVATED DOMESTIC BATTERY - OTHER DANGEROUS ...   \n",
       "3                                           OVER $500   \n",
       "4                                              SIMPLE   \n",
       "..                                                ...   \n",
       "95                                             SIMPLE   \n",
       "96                            DOMESTIC BATTERY SIMPLE   \n",
       "97                               AGG PRO.EMP: HANDGUN   \n",
       "98                                       RETAIL THEFT   \n",
       "99                       MANU/DELIVER: HEROIN (WHITE)   \n",
       "\n",
       "            Location Description  Arrest  Domestic  Year   Latitude  Longitude  \n",
       "0   COMMERCIAL / BUSINESS OFFICE   False     False  2019  41.751307 -87.603468  \n",
       "1             GROCERY FOOD STORE   False     False  2019  41.903997 -87.643230  \n",
       "2                 CLEANING STORE    True      True  2019  41.880329 -87.758473  \n",
       "3                         STREET   False     False  2019  41.924384 -87.641442  \n",
       "4                          ALLEY   False     False  2019  41.755797 -87.634426  \n",
       "..                           ...     ...       ...   ...        ...        ...  \n",
       "95                    RESTAURANT   False     False  2019  41.890384 -87.624110  \n",
       "96                     RESIDENCE   False     False  2019  41.921325 -87.779766  \n",
       "97       SCHOOL, PUBLIC, GROUNDS   False     False  2019  42.003359 -87.705800  \n",
       "98            GROCERY FOOD STORE   False     False  2019  42.019399 -87.675049  \n",
       "99            ABANDONED BUILDING    True     False  2019  41.877933 -87.729141  \n",
       "\n",
       "[100 rows x 11 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = 'https://github.com/jreades/fsds/raw/master/data/2019-sample-crime.csv'\n",
    "out = os.path.join('data','crime-sample.csv')\n",
    "\n",
    "ds = pd.read_csv(get_url(url, out))\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ds has 11 columns, these are: ID, Case Number, Date, Primary Type, Description, Location Description, Arrest, Domestic, Year, Latitude, Longitude\n",
      "There are 100 rows of data\n"
     ]
    }
   ],
   "source": [
    "print(f\"ds has {len(ds.keys())} columns, these are: \" + \", \".join(ds.keys()))\n",
    "print(f\"There are {len(ds['ID'])} rows of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.3 Use To_Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dtools\n",
    "cols  = ['Latitude', 'Longitude'] \n",
    "dtype = [float, float]\n",
    "\n",
    "typed_ds = {}\n",
    "for col in zip(cols, dtype): # <- This only copies these two columns to typed_ds\n",
    "    colname = col[0]\n",
    "    coltype = col[1]\n",
    "    typed_ds[ colname ] = dtools.to_type(ds[colname], coltype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.6.4 Use Find_Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = find_val(typed_ds['Latitude'], 'min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ds['Case Number'][idx])\n",
    "print(ds['Description'][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6. Brain Teaser\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\"><b>Difficulty level</b>: &#129327;.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now for something completely different!\n",
    "\n",
    "We want to create a set of 'ideal shapes' with methods allowing us to derive various properties of that shape:\n",
    "\n",
    "- Diameter: which we'll define as the longest line that can be drawn across the inside of the shape.\n",
    "- Volume: the total volume of the shape.\n",
    "- Surface Area: the total outside area of the shape.\n",
    "\n",
    "We will create all of these shape classes in the notebook so that we know they work and then will move them to an external package file so that they can be imported and re-used easily in other notebooks.\n",
    "\n",
    "We're also going to make use of a few features of Python:\n",
    "\n",
    "- You can access the class name of an instance using: `self.__class__.__name__`. And here's one key point: `self` refers to the instance, not to the class... we'll see why this matters.\n",
    "- You can raise your own exceptions easily if you don't want to implement a particular method yet.\n",
    "- You can have an 'abstract' base class that does nothing except provide a template for the 'real' classes so that they can be used interchangeably.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.1 Abstract Base Class\n",
    "\n",
    "This class appears to do very little, but there are two things to notice:\n",
    "\n",
    "1. It provides a constructor (`__init__`) that sets the `shape_type` to the name of the class automatically (so a `square` object has `shape_type='Square'`) and it stores the critical dimension of the shape in `self.dim`.\n",
    "2. It provides methods (which only raise exceptions) that will allow one shape to be used in the place of any other shape that inherits from `shape`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "\n",
    "# Base class shape\n",
    "class shape(object): # Inherit from base class \n",
    "    def __init__(self, dimension:float=None):\n",
    "        self.shape_type = self.__class__.__name__.capitalize()\n",
    "        self.dim = dimension\n",
    "        return\n",
    "    \n",
    "    def diameter(self):\n",
    "        raise Exception(\"Unimplmented method error.\")\n",
    "    \n",
    "    def volume(self):\n",
    "        raise Exception(\"Unimplmented method error.\")\n",
    "    \n",
    "    def surface(self):\n",
    "        raise Exception(\"Unimplmented method error.\")\n",
    "        \n",
    "    def type(self):\n",
    "        return(self.shape_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.2 Cube\n",
    "\n",
    "Implements a cube:\n",
    "\n",
    "1. The diameter of the cube is given by the Pythagorean formula for the length of the hypotenuse in 3D between opposing corners: $\\sqrt{d^{2} + d^{2} + d^{2}}$ which we can reduce to $\\sqrt{3 d^{2}}$.\n",
    "2. A cube's volume is given by $d^{3}$.\n",
    "3. A cube's surface area will be the sum of its six faces: $6d^{2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cube class\n",
    "class cube(shape): # Inherit from shape \n",
    "    def __init__(self, dim:float):\n",
    "        super().__init__(dim)\n",
    "        return\n",
    "    \n",
    "    def diameter(self):\n",
    "        return (3 * self.??**2)**(1/2)\n",
    "    \n",
    "    def volume(self):\n",
    "        return self.dim**3\n",
    "    \n",
    "    def surface(self):\n",
    "        return ??*(self.dim**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.3 Sphere\n",
    "\n",
    "Implements a sphere:\n",
    "\n",
    "1. The diameter is twice the critical dimension (radius): $2d$. \n",
    "2. The volume is $\\frac{4}{3} \\pi r^{3}$.\n",
    "3. The surface area will be $4 \\pi r^{2}$.\n",
    "\n",
    "If we were writing something more general, we'd probably have spheres as a special case of an ellipsoid!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sphere code here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.4 Regular Pyramid\n",
    "\n",
    "We're taking this to be a regular pyramid where all sides are equal: \n",
    "\n",
    "1. The diameter is a line drawn across the base between opposing corners of the base so it's just $\\sqrt{d^{2} + d^{2}}$.\n",
    "2. The volume is given by $V = b * h / 3$ (where $b$ is the area of the base, which in this case becomes $d^{2} * h/3$).\n",
    "3. The surface area will be the base + 4 equilateral triangles: $d^{2} + 4 (d^{2}\\sqrt{3}/4)$ which we can reduce to $d^{2} + d^{2}\\sqrt{3}$\n",
    "\n",
    "But this requires a _height_ method that is specific to pyramids:\n",
    "\n",
    "4. The height is taken from the centre of the pyramid (which will be half the length of the hypotenuse for two edges): $l = \\sqrt{d{^2} + d^{2}}$ and the long side ($d$ again) which gives us $\\sqrt{l/2 + d^{2}}$.\n",
    "\n",
    "Note that this has a class variable called `has_mummies` since Egyptian regular pyramids are plagued by them! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyramid class\n",
    "class pyramid(shape): # Inherit from shape\n",
    "    \n",
    "    has_mummies = True # This is for *all* regular pyramids\n",
    "    \n",
    "    def __init__(self, dim:float):\n",
    "        super().__init__(dim)\n",
    "        self.shape_type = 'Regular Pyramid'\n",
    "        return\n",
    "    \n",
    "    def diameter(self):\n",
    "        return (self.dim**?? + self.??**2)**(1/2)\n",
    "    \n",
    "    def height(self):\n",
    "        return (self.diameter()/?? + self.dim**2)**(1/2)\n",
    "    \n",
    "    def volume(self):\n",
    "        return self.dim**2 * self.??() / 3\n",
    "    \n",
    "    def surface(self):\n",
    "        return self.dim**2 + self.dim**2 * 3**(1/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.5 Triangular Pyramid\n",
    "\n",
    "We want triangular pyramid to inherit from regular pyramid, and all sides are equal so it's an _equilateral_ triangular pyramid. However, this is kind of a judgement call since there's very little shared between the two types of pyramid and it's arguable whether this one is actually simpler and should therefore be the parent class...\n",
    "\n",
    "Anyway, the calculations are:\n",
    "\n",
    "1. The diameter (longest line through the shape) will just be the edge: $d$.\n",
    "2. The volume $V = b * h / 3$ where $b$ is the area of an equilateral triangle.\n",
    "3. The surface area will be $4b$ where $b$ is the area of an equilateral triangle.\n",
    "\n",
    "So we now need two new formulas:\n",
    "\n",
    "5. The height of the pyramid using ([Pythagoras again](https://www.youtube.com/watch?v=ivF3ndmkMsE)): $h = \\sqrt{6}d/3$.\n",
    "6. The area of an equilateral triangle: $\\frac{\\sqrt{3}}{4} d^{2}$\n",
    "\n",
    "Triangular pyramids do *not* have a problem with mummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triangular pyramid code here (extends regular pyramid)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.6 Testing Your Classes\n",
    "\n",
    "If you've implemented everything correctly then the following code should run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How would you test these changes?\n",
    "s = sphere(10)\n",
    "print(s.type())\n",
    "print(f\"\\tVolume is: {s.volume():5.2f}\")\n",
    "print(f\"\\tDiameter is: {s.diameter():5.2f}\")\n",
    "print(f\"\\tSurface Area is: {s.surface():5.2f}\")\n",
    "print(\"\")\n",
    "\n",
    "c = cube(10)\n",
    "print(c.type())\n",
    "print(f\"\\tVolume is: {c.volume():5.2f}\")\n",
    "print(f\"\\tDiameter is: {c.diameter():5.2f}\")\n",
    "print(f\"\\tSurface Area is: {c.surface():5.2f}\")\n",
    "print(\"\")\n",
    "\n",
    "p = pyramid(10)\n",
    "print(p.type())\n",
    "print(f\"\\tVolume is: {p.volume():5.2f}\")\n",
    "print(f\"\\tDiameter is: {p.diameter():5.2f}\")\n",
    "print(f\"\\tSurface Area is: {p.surface():5.2f}\")\n",
    "print(f\"\\tHeight is: {p.height():5.2f}\")\n",
    "if p.has_mummies is True:\n",
    "    print(\"\\tMummies? Aaaaaaaaagh!\")\n",
    "else:\n",
    "    print(\"\\tPhew, no mummies!\")\n",
    "print(\"\")\n",
    "\n",
    "p2 = t_pyramid(10)\n",
    "print(p2.type())\n",
    "print(f\"\\tVolume is: {p2.volume():5.2f}\")\n",
    "print(f\"\\tDiameter is: {p2.diameter():5.2f}\")\n",
    "print(f\"\\tSurface Area is: {p2.surface():5.2f}\")\n",
    "print(f\"\\tHeight is: {p2.height():5.2f}\")\n",
    "if p2.has_mummies is True:\n",
    "    print(\"\\tMummies? Aaaaaaaaagh!\")\n",
    "else:\n",
    "    print(\"\\tPhew, no mummies!\")\n",
    "print(\"\")\n",
    "\n",
    "# Useful demonstration of how to find out if a method or attribute is\n",
    "# associated with a particular object\n",
    "if hasattr(p2,'base_area'):\n",
    "    print(f\"Shape of type '{p2.type()}' has attribute or method 'base_area'\")\n",
    "else:\n",
    "    print(f\"Shape of type '{p2.type()}' does *not* have attribute or method 'base_area'\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I get the following output:\n",
    "\n",
    "```\n",
    "Sphere\n",
    "\tVolume is: 4188.79\n",
    "\tDiameter is: 20.00\n",
    "\tSurface Area is: 1256.64\n",
    "\n",
    "Cube\n",
    "\tVolume is: 1000.00\n",
    "\tDiameter is: 17.32\n",
    "\tSurface Area is: 600.00\n",
    "\n",
    "Regular Pyramid\n",
    "\tVolume is: 344.92\n",
    "\tDiameter is: 14.14\n",
    "\tSurface Area is: 273.21\n",
    "\tHeight is: 10.35\n",
    "\tMummies? Aaaaaaaaagh!\n",
    "\n",
    "Triangular Pyramid\n",
    "\tVolume is: 117.85\n",
    "\tDiameter is: 10.00\n",
    "\tSurface Area is: 173.21\n",
    "\tHeight is:  8.16\n",
    "\tPhew, no mummies!\n",
    "\n",
    "Shape of type 'Triangular Pyramid' does *not* have attribute or method 'base_area'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6.7 Packaging It Up\n",
    "\n",
    "Wait, you're *still* working on this practical and haven't thrown up your hands in disgust yet? OK, in that case you can have *one* more thing to do: turn the whole shapes class hierarchy into a package that can be loaded via an `import` statement. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.1 Cell Magic\n",
    "\n",
    "This code allows Jupyter to reload external libraries if they are edited after you import them. When you are working on your own packages this is rather useful since you tend to make a *lot* of mistakes when packaging code up this way and it's handy not to have to restart the entire notebook every time you fix a typo or change a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.2 Import Shapes\n",
    "\n",
    "You can call your package whatever you like, but then it *has* to match what you `import` below. So remember that with `dtools` we had `dtools/__init__.py`? You'll need to do the same here so that you can import the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shapes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [90]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshapes\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shapes'"
     ]
    }
   ],
   "source": [
    "import shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.7.3 Adding Documentation\n",
    "\n",
    "In an ideal world, this would also be the time to properly document your classes and methods. Here as some examples that you could add to the `__init__.py` package file.\n",
    "\n",
    "Underneath the line `class shape(object):`, add:\n",
    "```\n",
    "    \"\"\"Abstract base class for all ideal shape classes.\n",
    "\n",
    "    Keyword arguments:\n",
    "    dimension -- the principle dimension of the shape (default None)\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "Underneath the line `def type(self):`, add:\n",
    "```\n",
    "        \"\"\"\n",
    "        Returns the formatted name of the shape type. \n",
    "        \n",
    "        This is set automatically, but can be overwritten by setting the attribute shape_type.\n",
    "        \n",
    "        :returns: the name of the class, so shapes.cube is a `Cube` shape type\n",
    "        :rtype: str\n",
    "        \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'shapes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [89]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshapes\u001b[39;00m \u001b[38;5;66;03m# <-- Change this if you didn't call your package `shapes`!\u001b[39;00m\n\u001b[1;32m      2\u001b[0m help(shapes\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m help(shapes\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mtype)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'shapes'"
     ]
    }
   ],
   "source": [
    "import shapes # <-- Change this if you didn't call your package `shapes`!\n",
    "help(shapes.shape)\n",
    "help(shapes.shape.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
